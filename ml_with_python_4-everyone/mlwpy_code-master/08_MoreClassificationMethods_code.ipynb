{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "from mlwpy import *\n",
    "%matplotlib inline\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# standard iris dataset\n",
    "tts = skms.train_test_split(iris.data, iris.target, \n",
    "                            test_size=.33, random_state=21)\n",
    "(iris_train_ftrs, iris_test_ftrs, \n",
    " iris_train_tgt,  iris_test_tgt) = tts\n",
    "\n",
    "# one-class variation\n",
    "useclass = 1\n",
    "tts_1c = skms.train_test_split(iris.data, iris.target==useclass, \n",
    "                               test_size=.33, random_state = 21)\n",
    "(iris_1c_train_ftrs, iris_1c_test_ftrs, \n",
    " iris_1c_train_tgt,  iris_1c_test_tgt) = tts_1c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_classifiers = {'DTC' : tree.DecisionTreeClassifier(max_depth=3)}\n",
    "\n",
    "fig, ax = plt.subplots(1,1,figsize=(4,3))\n",
    "for name, mod in tree_classifiers.items():\n",
    "    # plot_boundary only uses specified columns\n",
    "    # [0,1] [sepal len/width] to predict and graph.  \n",
    "    plot_boundary(ax, iris.data, iris.target, mod, [0,1])\n",
    "    ax.set_title(name)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = tree.DecisionTreeClassifier()\n",
    "skms.cross_val_score(dtc, \n",
    "                     iris.data, iris.target, \n",
    "                     cv=3, scoring='accuracy') # sorry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_1c_tree = (tree.DecisionTreeClassifier()\n",
    "                    .fit(iris_1c_train_ftrs, iris_1c_train_tgt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using an additional library\n",
    "# conda install pydotplus\n",
    "# pip install pydotplus\n",
    "import pydotplus \n",
    "dot_data = tree.export_graphviz(iris_1c_tree, out_file=None) \n",
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "graph.write_png(\"outputs/iris_1c.png\")\n",
    "Image(\"outputs/iris_1c.png\", width=75, height=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_tree = (tree.DecisionTreeClassifier()\n",
    "                 .fit(iris_train_ftrs, iris_train_tgt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no added lib. to produce .dot file\n",
    "with open(\"outputs/iris.dot\", 'w') as f:\n",
    "    dot_data = tree.export_graphviz(iris_tree, out_file=f, \n",
    "                                    feature_names=iris.feature_names,  \n",
    "                                    class_names=iris.target_names,  \n",
    "                                    filled=True, rounded=True)\n",
    "\n",
    "# the following '!' lines are \"shell\" commands\n",
    "# uses the 'dot' program to convert to dot -> png\n",
    "!dot -Tpng outputs/iris.dot -o outputs/iris.png\n",
    "!rm outputs/iris.dot\n",
    "\n",
    "Image(\"outputs/iris.png\", width=140, height=140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,2,figsize=(4,4))\n",
    "\n",
    "depths = [1, 2, 3, None]\n",
    "for depth, ax in zip(depths, axes.flat):\n",
    "    dtc_model = tree.DecisionTreeClassifier(max_depth=depth)\n",
    "    # plot_boundary only uses specified columns [0,1]\n",
    "    # so we are only predicting with sepal length and width\n",
    "    plot_boundary(ax, iris.data, iris.target, dtc_model, [0,1])\n",
    "    ax.set_title(\"DTC (max_depth={})\".format(dtc_model.max_depth))\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(4,3))\n",
    "\n",
    "# fancy way to get cross-product of points\n",
    "left  = np.mgrid[1:4.0, 1:10].reshape(2, -1).T\n",
    "right = np.mgrid[6:9.0, 1:10].reshape(2, -1).T\n",
    "\n",
    "# data points\n",
    "ax.scatter(left[:,0] , left[:,1] , c='b', marker='x')\n",
    "ax.scatter(right[:,0], right[:,1], c='r', marker='o')\n",
    "\n",
    "# separating lines\n",
    "ax.plot([3.5, 5.5], [1,9], 'y', label='A')\n",
    "ax.plot([4.5, 4.5], [1,9], 'k', label='B')\n",
    "ax.plot([3.5, 5.5], [9,1], 'g', label='C')\n",
    "ax.legend(loc='lower center');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(4,3))\n",
    "\n",
    "# fancy way to get cross-product of points\n",
    "left  = np.mgrid[1:4:2, 1:10].reshape(2, -1).T\n",
    "right = np.mgrid[6:9:2, 1:10].reshape(2, -1).T\n",
    "\n",
    "ax.scatter(left[:,0] , left[:,1] , c='b', marker='x')\n",
    "ax.scatter([2,2], [1,9], c='b', marker='x')\n",
    "ax.scatter(right[:,0], right[:,1], c='r', marker='o')\n",
    "ax.scatter([7,7], [1,9], c='r', marker='o')\n",
    "ax.set_xlim(0,9);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(4,3))\n",
    "\n",
    "left  = np.mgrid[3:4, 1:10].reshape(2, -1).T\n",
    "right = np.mgrid[6:7, 1:10].reshape(2, -1).T\n",
    "\n",
    "ax.scatter(left[:,0] , left[:,1] , c='b', marker='x')\n",
    "ax.scatter(right[:,0], right[:,1], c='r', marker='o')\n",
    "ax.set_xlim(0,9);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_classifiers = {\"SVC(Linear)\"   : svm.SVC(kernel='linear'),\n",
    "                  \"NuSVC(Linear)\" : svm.NuSVC(kernel='linear', nu=.9)} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2,figsize=(6,3))\n",
    "for (name, mod), ax in zip(sv_classifiers.items(), axes.flat):\n",
    "    plot_boundary(ax, iris.data, iris.target, mod, [0,1])\n",
    "    ax.set_title(name)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_linear_svc_separators(svc_maker, pname, params, ax):\n",
    "    'create svc(params) and draw seperation boundary'\n",
    "    xys = (np.linspace(2,8,100),\n",
    "           np.linspace(2,8,100))\n",
    "\n",
    "    for p in params:\n",
    "        kwargs = {pname:p, 'kernel':'linear'}\n",
    "        svc = svc_maker(**kwargs).fit(ftrs, tgt)\n",
    "        # plot_separator is in mlwpy.py\n",
    "        plot_separator(svc, *xys, \n",
    "                       '{}={:g}'.format(pname, p), ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftrs = np.array([[3,3],\n",
    "                 [3,6],\n",
    "                 [7,3],\n",
    "                 [7,6],\n",
    "                 [6,3]])\n",
    "tgt  = np.array([0,0,1,1,0])\n",
    "colors = np.array(['r', 'b'])\n",
    "\n",
    "Cs = [.1, 1.0, 10]\n",
    "nus = [.3, .4, .5]\n",
    "\n",
    "fig, axes = plt.subplots(1,3,figsize=(12,4),\n",
    "                         sharex=True, sharey=True)\n",
    "for ax in axes:\n",
    "    ax.scatter(ftrs[:,0], ftrs[:,1], c=colors[tgt])\n",
    "ax.set_xlim(2,8); ax.set_ylim(2,7)\n",
    "\n",
    "do_linear_svc_separators(svm.SVC,   \"C\",   Cs, axes[1])\n",
    "do_linear_svc_separators(svm.NuSVC, \"nu\", nus, axes[2])\n",
    "\n",
    "axes[0].set_title(\"No Boundary\")\n",
    "axes[1].set_title(\"C Boundaries\")\n",
    "axes[2].set_title(r\"$\\nu$ Boundaries\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftrs, tgt = datasets.make_blobs(centers=2,\n",
    "                                n_features=3,\n",
    "                                n_samples=200,\n",
    "                                center_box = [-2.0, 2.0],\n",
    "                                random_state=1099)\n",
    "\n",
    "# note, using three features, but graphing only two dimensions\n",
    "fig, ax = plt.subplots(1,1,figsize=(4,3))\n",
    "ax.scatter(ftrs[:, 0], ftrs[:, 1], \n",
    "           marker='o', c=tgt, s=25, edgecolor='k')\n",
    "ax.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjusted to remove infeasible nu values\n",
    "nus = np.linspace(0.05, .85, 9)\n",
    "tt = skms.validation_curve(svm.NuSVC(kernel='linear'), \n",
    "                           ftrs, tgt, \n",
    "                           param_name='nu',\n",
    "                           param_range=nus,\n",
    "                           cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(4,3))\n",
    "\n",
    "tidy_df = sk_graph_to_tidy(tt, nus, 'nu', 5)\n",
    "ax = sns.lineplot(x='nu', y='score', hue='set', data=tidy_df)\n",
    "\n",
    "ax.set_title('5-fold CV Performance for NuSVC')\n",
    "ax.set_xlabel(\"\\n\".join([r'$\\nu$ for $\\nu$-SVC']))\n",
    "ax.set_ylim(.3, 1.01)\n",
    "ax.legend(loc='lower center');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated to use lineplot in place of deprecated tsplot; \n",
    "# kept for comparison with above\n",
    "if False:\n",
    "    fig,ax = plt.subplots(1,1,figsize=(4,3))\n",
    "    ax = sns.tsplot(np.array(tt).transpose(), \n",
    "                   time=nus, \n",
    "                   condition=['Train', 'Test'], \n",
    "                   interpolate=False)\n",
    "\n",
    "    ax.set_title('5-fold CV Performance for NuSVC')\n",
    "    ax.set_xlabel(\"\\n\".join([r'$\\nu$ for $\\nu$-SVC']))\n",
    "    ax.set_ylim(.3, 1.01)\n",
    "    ax.legend(loc='lower center');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = [0.0001, 0.001, 0.01, .1, 1.0, 10, 100, 1000]\n",
    "tt = skms.validation_curve(svm.SVC(kernel='linear'), \n",
    "                           ftrs, tgt, \n",
    "                           param_name='C',\n",
    "                           param_range=cs,\n",
    "                           cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(4,3))\n",
    "\n",
    "tidy_df = sk_graph_to_tidy(tt, cs, 'c', 5)\n",
    "ax = sns.lineplot(x='c',y='score',hue='set',data=tidy_df)\n",
    "\n",
    "ax.set_title('5-fold CV Performance for SVC')\n",
    "ax.set_xlabel(\"\\n\".join([r'C for SVC']))\n",
    "ax.set_ylim(.8, 1.01)\n",
    "ax.set_xlim(.00001, 10001)\n",
    "ax.set_xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated to use lineplot in place of deprecated tsplot; \n",
    "# kept for comparison with above\n",
    "if False:\n",
    "    fig,ax = plt.subplots(1,1,figsize=(4,3))\n",
    "    ax = sns.tsplot(np.array(tt).transpose(), \n",
    "                    time=cs, \n",
    "                    condition=['Train', 'Test'], \n",
    "                    interpolate=False)\n",
    "\n",
    "    ax.set_title('5-fold CV Performance for SVC')\n",
    "    ax.set_xlabel(\"\\n\".join([r'C for SVC']))\n",
    "    ax.set_ylim(.8, 1.01)\n",
    "    ax.set_xlim(.00001, 10001)\n",
    "    ax.set_xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_argmax(arr):\n",
    "    ' helper to convert np.argmax into something usable '\n",
    "    return np.array(np.unravel_index(np.argmax(arr), \n",
    "                                     arr.shape))\n",
    "\n",
    "def df_names(df, idxs):\n",
    "    ' helper to convert number of index/column labels '\n",
    "    r,c = idxs\n",
    "    return df.index[r], df.columns[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_bets = np.arange(1,12,2)\n",
    "mark_bet, andy_bet = np.meshgrid(base_bets, base_bets)\n",
    "\n",
    "mark_winnings = .1 * andy_bet + .9 * -mark_bet\n",
    "\n",
    "df = pd.DataFrame(mark_winnings, \n",
    "                  index  =base_bets, \n",
    "                  columns=base_bets)\n",
    "df.index.name = \"Andy Bet\"\n",
    "df.columns.name = \"Mark Bet\"\n",
    "\n",
    "print(\"Best Betting Scenario (for Mark) for These Values:\")\n",
    "print(\"(Andy, Mark):\", df_names(df, simple_argmax(mark_winnings)))\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tail_probs = [0.0, .001, .01, .05, .10, .25, 1.0/3.0]\n",
    "\n",
    "lwr_probs = np.array(tail_probs)\n",
    "upr_probs = 1-lwr_probs[::-1]\n",
    "cent_prob = np.array([.5])\n",
    "\n",
    "probs = np.concatenate([lwr_probs, cent_prob, upr_probs])\n",
    "\n",
    "# much better than geterr/seterr/seterr\n",
    "with np.errstate(divide='ignore'):\n",
    "    odds     = probs / (1-probs)\n",
    "    log_odds = np.log(odds)\n",
    "\n",
    "index=[\"{:4.1f}%\".format(p) for p in np.round(probs,3)*100]\n",
    "\n",
    "polo_dict = co.OrderedDict([(\"Prob(E)\",       probs), \n",
    "                            (\"Odds(E:not E)\", odds), \n",
    "                            (\"Log-Odds\",      log_odds)])\n",
    "polo_df = pd.DataFrame(polo_dict, index=index)\n",
    "polo_df.index.name=\"Pct(%)\"\n",
    "polo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def helper(ax,x,y,x_name,y_name):\n",
    "    ax.plot(x,y, 'r--o')\n",
    "    ax.set_xlabel(x_name)\n",
    "    ax.set_ylabel(y_name)\n",
    "\n",
    "# note, we trim the values above 90% [index -5] b/c \n",
    "# the scale of the plots gets too compressed\n",
    "# (huh, log-scale takes care of that! funny .....)\n",
    "fig, (ax0, ax1) = plt.subplots(1,2, figsize=(9,3))\n",
    "helper(ax0, probs[:-5], odds[:-5], 'probability', 'odds')\n",
    "helper(ax1, odds[:-5], probs[:-5], 'odds', 'probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax0, ax1) = plt.subplots(1,2, figsize=(9,3))\n",
    "helper(ax0, probs, log_odds, 'probability', 'log-odds')\n",
    "helper(ax1, log_odds, probs, 'log-odds', 'probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([polo_df.min(axis=0),\n",
    "              polo_df.max(axis=0)], index=['min', 'max']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit(probs):\n",
    "    odds = probs / (1-probs)\n",
    "    log_odds = np.log(odds)\n",
    "    return log_odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Both options come with \"regularization\" turned ON, \n",
    "# we'll ignore that for now, but see Chapter 9 for more details\n",
    "LogReg = linear_model.LogisticRegression\n",
    "SGD    = linear_model.SGDClassifier\n",
    "logreg_classifiers = {'LogReg(saga)': LogReg(solver='saga', \n",
    "                                             multi_class='multinomial',\n",
    "                                             max_iter=1000),\n",
    "                      'LogReg(SGD)' :  SGD(loss='log', max_iter=1000)}\n",
    "\n",
    "fig, axes = plt.subplots(1,2,figsize=(12,4))\n",
    "axes = axes.flat\n",
    "for (name, mod), ax in zip(logreg_classifiers.items(), axes):\n",
    "    plot_boundary(ax, iris.data, iris.target, mod, [0,1])\n",
    "    ax.set_title(name)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(4,1))\n",
    "\n",
    "x = np.array([1,2,5,10]).reshape(-1, 1)\n",
    "y = ['red', 'blue', 'red', 'blue']\n",
    "ax.scatter(x,np.zeros_like(x), c=y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note:  different import source\n",
    "import statsmodels.api as sm\n",
    "\n",
    "x = np.c_[x, np.ones_like(x)] # +1 trick\n",
    "tgt = (np.array(y) == 'red')\n",
    "\n",
    "# sm.Logit is statsmodels name for logistic regression\n",
    "(sm.Logit(tgt, x, method='newton')\n",
    "   .fit()\n",
    "   .predict(x))  # training predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(4,1))\n",
    "\n",
    "x = np.array([1,4,6,10]).reshape(-1, 1)\n",
    "y = ['red', 'red', 'blue', 'blue']\n",
    "ax.scatter(x, np.zeros_like(x), c=y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.c_[x, np.ones_like(x)] # +1 trick\n",
    "tgt = (np.array(y) == 'red')\n",
    "try:\n",
    "    (sm.Logit(tgt, x, method='newton')\n",
    "       .fit()\n",
    "       .predict(x)) # in-sample predictions\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([1,3,5,10,20])\n",
    "n = len(X)\n",
    "\n",
    "mean_X = sum(X) / n\n",
    "errors = X - mean_X\n",
    "var_X = np.dot(errors, errors) / n\n",
    "\n",
    "fmt = \"long way: {}\\nbuilt in: {}\\n   close: {}\"\n",
    "print(fmt.format(var_X, \n",
    "                 np.var(X), \n",
    "                 np.allclose(var_X, np.var(X)))) # phew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([1,3,5,10,20])\n",
    "Y = np.array([2,4,1,-2,12])\n",
    "\n",
    "mean_X = sum(X) / n\n",
    "mean_Y = sum(Y) / n\n",
    "\n",
    "errors_X = X - mean_X\n",
    "errors_Y = Y - mean_Y\n",
    "\n",
    "cov_XY = np.dot(errors_X, errors_Y) / n\n",
    "print(\"long way: {:5.2f}\".format(cov_XY))\n",
    "print(\"built in:\", np.cov(X,Y,bias=True)[0,1])\n",
    "# note:\n",
    "# np.cov(X,Y,bias=True) gives [Cov(X,X), Cov(X,Y)\n",
    "#                              Cov(Y,X), Cov(Y,Y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_x = 0\n",
    "n = len(X)\n",
    "for i in range(n):\n",
    "    for j in range(i, n): # rest of Xs\n",
    "        var_x += (X[i] - X[j])**2\n",
    "print(\"Var(X):\", var_x / n**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_xy = 0\n",
    "for i in range(len(X)):\n",
    "    for j in range(i, len(X)): # rest of Xs, Ys\n",
    "        cov_xy += (X[i] - X[j])*(Y[i]-Y[j])\n",
    "print(\"Cov(X,Y):\", cov_xy / n**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_XY = 0.0\n",
    "xy_pairs = it.product(zip(X,Y), repeat=2)\n",
    "for (x_i, y_i), (x_j,y_j) in xy_pairs:\n",
    "    cov_XY += (x_i - x_j) * (y_i - y_j)\n",
    "print(\"Cov(X,Y):\", cov_XY / (2 * n**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_XX = 0.0\n",
    "for x_i, x_j in it.combinations(X, 2):\n",
    "    cov_XX += (x_i - x_j)**2\n",
    "print(\"Cov(X,X) == Var(X):\", cov_XX / (n**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_XY = 0.0\n",
    "for (x_i, y_i), (x_j,y_j) in it.combinations(zip(X,Y), 2):\n",
    "    cov_XY += (x_i - x_j) * (y_i - y_j)\n",
    "print(\"Cov(X,Y):\", cov_XY / (n**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# color coding\n",
    "# -inf -> 0; 0 -> .5; inf -> 1\n",
    "# slowly at the tails; quickly in the middle (near 0)\n",
    "def sigmoid(x):  \n",
    "    return np.exp(-np.logaddexp(0, -x))\n",
    "\n",
    "# to get the colors we need, we have to build a raw array\n",
    "# with the correct values.  we are really \"drawing\"\n",
    "# inside a numpy array, not on the screen\n",
    "def draw_rectangle(arr, pt1, pt2):\n",
    "    (x1,y1),(x2,y2) = pt1,pt2\n",
    "    delta_x, delta_y = x2-x1, y2-y1\n",
    "    r,c = min(y1,y2), min(x1,x2)  # x,y -> r,c\n",
    "    # assign +/- 1 to each block in the rectangle.  \n",
    "    # total summation value equals area of rectangle (signed for up/down)\n",
    "    arr[r:r+abs(delta_y), \n",
    "        c:c+abs(delta_x)] += np.sign(delta_x * delta_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our data points:\n",
    "pts = [(1,1), (3,6), (6,3)]\n",
    "pt_array = np.array(pts, dtype=np.float64)\n",
    "\n",
    "# the array we are \"drawing\" on:\n",
    "draw_arr = np.zeros((10,10))\n",
    "ct = len(pts)\n",
    "c_magic = 1 / ct**2 # without double counting\n",
    "\n",
    "# we use the clever, don't double count method\n",
    "for pt1, pt2 in it.combinations(pts, 2):\n",
    "    draw_rectangle(draw_arr, pt1, pt2)\n",
    "draw_arr *= c_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the array we drew\n",
    "from matplotlib import cm\n",
    "fig, ax = plt.subplots(1,1,figsize=(4,3))\n",
    "ax.matshow(sigmoid(draw_arr), origin='lower', cmap=cm.bwr, vmin=0, vmax=1)\n",
    "fig.tight_layout()\n",
    "\n",
    "# show a diagonal across each rectangles\n",
    "# the array elements are centered in each grid square\n",
    "ax.plot([ .5, 2.5],[ .5, 5.5], 'r')  # from 1,1 to 3,6 \n",
    "ax.plot([ .5, 5.5],[ .5, 2.5], 'r')  # from 1,1 to 6,3\n",
    "ax.plot([2.5, 5.5],[5.5, 2.5], 'b');  # from 3,6 to 6,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_cov = np.cov(pt_array[:,0], pt_array[:,1], bias=True)[0,1]\n",
    "print(\"Cov(x,y) -   from numpy: {:4.2f}\".format(np_cov))\n",
    "\n",
    "# show the covariance, as calculated from our drawing\n",
    "print(\"Cov(x,y) - our long way: {:4.2f}\".format(draw_arr.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4.5,4.5))\n",
    "hm = sns.heatmap(draw_arr, center=0, \n",
    "                 square=True, annot=True, \n",
    "                 cmap='bwr', fmt=\".1f\")\n",
    "hm.invert_yaxis()\n",
    "hm.tick_params(bottom=False, left=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'X':[ 1, 3, 6], \n",
    "                     'Y':[ 1, 6, 3], \n",
    "                     'Z':[10, 5, 1]})\n",
    "data.index.name = 'examples'\n",
    "\n",
    "# it's not critical to these examples, but Panda's cov is \n",
    "# \"unbiased\" and we've been working with \"biased\" cov.\n",
    "# see EOC notes for details\n",
    "display(data)\n",
    "print(\"Covariance:\")\n",
    "display(data.cov())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'x':[ 3, 6, 3, 4], \n",
    "                     'y':[ 9, 6, 3, 0],\n",
    "                     'z':[ 1, 4, 7, 0]})\n",
    "data.index.name = 'examples'\n",
    "display(data)\n",
    "print(\"Covariance:\")\n",
    "display(data.cov()) # biased covariance, see EOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(4,3))\n",
    "data.plot(ax=ax)\n",
    "ax.vlines([0,1,2,3], 0, 10, colors=\".5\")\n",
    "\n",
    "ax.legend(loc='lower center', ncol=3)\n",
    "\n",
    "plt.box(False)\n",
    "ax.set_xticks([0,1,2,3])\n",
    "ax.set_ylabel(\"values\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda  = discriminant_analysis.QuadraticDiscriminantAnalysis()\n",
    "lda  = discriminant_analysis.LinearDiscriminantAnalysis()\n",
    "nb   = naive_bayes.GaussianNB()\n",
    "dlda = DLDA() # from mlwpy.py\n",
    "\n",
    "da_methods = [qda, lda, nb, dlda]\n",
    "names = [\"QDA\", \"LDA\", \"NB\", \"DLDA\"]\n",
    "    \n",
    "fig, axes = plt.subplots(2,2, figsize=(4.5, 4.5),\n",
    "                         sharex=True, sharey = True)\n",
    "for ax, model, name in zip(axes.flat, da_methods, names):\n",
    "    preds = (model.fit(iris_train_ftrs, iris_train_tgt)\n",
    "                  .predict(iris_test_ftrs))\n",
    "    cm = metrics.confusion_matrix(iris_test_tgt, preds)\n",
    "    sns.heatmap(cm, annot=True, cbar=False, ax=ax)\n",
    "    ax.set_title(name)\n",
    "\n",
    "axes[0,0].set_ylabel('Actual')\n",
    "axes[1,0].set_xlabel('Predicted');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2,2,figsize=(4.5, 4.5))\n",
    "axes = axes.flat\n",
    "\n",
    "for model, ax, name in zip(da_methods, axes, names):\n",
    "    # plot boundary only uses the specified (two) dimensions to predict\n",
    "    plot_boundary(ax, iris.data, iris.target, model, [0,1])\n",
    "    ax.set_title(name)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftrs = np.mgrid[1:10, 1:10].T.reshape(-1,2)\n",
    "tgt  = ftrs[:,0] > ftrs[:,1]\n",
    "\n",
    "fig, axes = plt.subplots(1,3,figsize=(9,3))\n",
    "axes = axes.flat\n",
    "\n",
    "svc = svm.SVC(kernel='linear')\n",
    "dt_shallow  = tree.DecisionTreeClassifier(max_depth=3)\n",
    "dt_deep     = tree.DecisionTreeClassifier()\n",
    "models = [svc, dt_shallow, dt_deep]\n",
    "\n",
    "for model, ax in zip(models, axes):\n",
    "    # plot boundary only uses the specified (two) dimensions to predict\n",
    "    plot_boundary(ax, ftrs, tgt, model, [0,1])\n",
    "    ax.set_title(get_model_name(model))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape:\", digits.images[0].shape)\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(digits.images[0], cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits.target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_parade = \\\n",
    "    {'LogReg(1)' : linear_model.LogisticRegression(max_iter=1000),\n",
    "     'LogReg(2)' : linear_model.SGDClassifier(loss='log',\n",
    "                                              max_iter=1000),\n",
    "\n",
    "     'QDA' : discriminant_analysis.QuadraticDiscriminantAnalysis(),\n",
    "     'LDA' : discriminant_analysis.LinearDiscriminantAnalysis(),\n",
    "     'GNB' : naive_bayes.GaussianNB(),\n",
    "\n",
    "     'SVC(1)' : svm.SVC(kernel=\"linear\"),\n",
    "     'SVC(2)' : svm.LinearSVC(),\n",
    "\n",
    "     'DTC'    : tree.DecisionTreeClassifier(),\n",
    "     '5NN-C'  : neighbors.KNeighborsClassifier(),\n",
    "     '10NN-C' : neighbors.KNeighborsClassifier(n_neighbors=10)}\n",
    "\n",
    "baseline = dummy.DummyClassifier(strategy=\"uniform\")\n",
    "\n",
    "base_score = skms.cross_val_score(baseline, digits.data, digits.target==1, \n",
    "                                  cv=10, scoring='average_precision', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "ax.plot(base_score, label='base')\n",
    "for name, model in classifier_parade.items():    \n",
    "    cv_scores = skms.cross_val_score(model, \n",
    "                                     digits.data, digits.target, \n",
    "                                     cv=10, \n",
    "                                     scoring='f1_macro', \n",
    "                                     n_jobs=-1) # all CPUs\n",
    "    my_lbl = \"{} {:.3f}\".format(name, cv_scores.mean())\n",
    "    ax.plot(cv_scores, label=my_lbl, marker=next(markers))\n",
    "ax.set_ylim(0.0, 1.1)\n",
    "ax.set_xlabel('Fold')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.legend(loc='lower center', ncol=2);"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
